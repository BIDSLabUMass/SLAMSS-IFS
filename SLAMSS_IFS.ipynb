{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import scipy.io\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "from numpy import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10#100\n",
    "BATCH_SIZEV = 13#560\n",
    "BATCH_SIZEV2 = 32\n",
    "\n",
    "# longest epoch len in the validation set\n",
    "len_val = 1150\n",
    "EPOCH = 1000\n",
    "h = 600\n",
    "w = 2\n",
    "in_w = 2\n",
    "sqe = 1200 # can try 5\n",
    "cls = 4\n",
    "crop = 600#1240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode_micro(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encode_micro, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(2, 32, 2, bidirectional = True, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(32*2, 128),\n",
    "        )\n",
    "     \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        outputs, hidden = self.rnn(src)\n",
    "        hidden = self.fc(outputs[:,-1,:])\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.GRU(2, 64, 3, bidirectional = True, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.cnn = nn.Sequential( \n",
    "        nn.Conv1d(2, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.MaxPool1d(6, stride=6),#60\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        #nn.Dropout(0.5),\n",
    "        #nn.MaxPool1d(3, stride=3),#20\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.MaxPool1d(5, stride=5),#10\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        # #nn.MaxPool1d(2, stride=2),#5\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # #nn.MaxPool1d(2, stride=2),#2\n",
    "        # nn.Conv1d(128, 256, 9, stride=1, padding=4),     \n",
    "        nn.Dropout(0.5),\n",
    "        #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        )\n",
    "         \n",
    "        self.cnn_ACT = nn.Sequential( \n",
    "        nn.Conv1d(5, 16, 9, stride=1, padding=4),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(16, 32, 9, stride=1, padding=4),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(32, 64, 9, stride=1, padding=4),\n",
    "        nn.Dropout(0.5),\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential( \n",
    "        nn.Conv1d(128+64+128, 256, 11, stride=1, padding=5),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(256, 256, 15, stride=1, padding=7),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(256, 512, 21, stride=1, padding=10),\n",
    "        nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "    def forward(self, src, time):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        src1 = src.permute(0, 2, 1)\n",
    "        src11 = time.permute(0, 2, 1)\n",
    "        #print(src1.size())\n",
    "        src2 = self.cnn(src1)\n",
    "        outputs, hidden = self.rnn(src)\n",
    "        outputs = outputs[:,::30,:]\n",
    "        src22 = outputs.permute(0, 2, 1)\n",
    "        src222 = self.cnn_ACT(src11)\n",
    "        #print src2.size()\n",
    "        #outputs2 = outputs.permute(0, 2, 1)\n",
    "        #src3= torch.cat((src11 src2),1)\n",
    "        src3= torch.cat((src2, src22, src222),1)\n",
    "        src4 = self.cnn3(src3)\n",
    "        src4= torch.cat((src4, src11[:,:,:]),1)\n",
    "        src5 = src4.permute(0, 2, 1)\n",
    "        \n",
    "\n",
    "        return src5\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 1) + dec_hid_dim, dec_hid_dim, bias=True)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        \n",
    "        #repeat encoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.rnn = nn.GRU(512+5, enc_hid_dim, 1, bidirectional = False, dropout=0.2, batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(enc_hid_dim * 1, dec_hid_dim, bias=True),\n",
    "        )\n",
    "     \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "\n",
    "\n",
    "        outputs, hidden = self.rnn(src)\n",
    "\n",
    "\n",
    "        hidden = self.fc(hidden[-1,:,:])\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 1 ) + emb_dim, dec_hid_dim,1, bidirectional = False, batch_first = True, dropout=0.2)\n",
    "        self.out = nn.Sequential( \n",
    "\n",
    "            nn.Linear((enc_hid_dim * 1) + dec_hid_dim + emb_dim + 512+5 + 128, output_dim),\n",
    "            #nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, cnnf, micro):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        #a = [batch size, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        #a = [batch size, 1, src len]\n",
    "        encoder_outputs = encoder_outputs.permute(0, 1, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "\n",
    "        rnn_input = torch.cat((input, weighted), dim = 2)\n",
    "\n",
    "        rnn_input = rnn_input.permute(1, 0, 2)\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        output = output.unsqueeze(0)\n",
    "        cnnf = cnnf.unsqueeze(0)\n",
    "        micro=micro.unsqueeze(0)\n",
    "\n",
    "        output = self.out(torch.cat((output, weighted, input, cnnf, micro), dim = 2))\n",
    "\n",
    "        return output, hidden.squeeze(0)\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device = 0):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.rnn = Encode_micro()\n",
    "        print(self.device)\n",
    "\n",
    "        \n",
    "    def forward(self, src, src2, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        batch_size = trg.shape[0]\n",
    "        max_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        input = trg[:,0]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        for t in range(0, max_len):\n",
    "            out, hid = self.rnn(src2[:,t*30:(t+1)*30,:])\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs, src[:,t,:],hid)\n",
    "            if output.size()[0] == 1:\n",
    "                outputs[:,t,:] = output[:,:]\n",
    "            else:\n",
    "                outputs[:,t,:] = output[:,0,:]\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[:,t] if teacher_force else output.squeeze(0)\n",
    "        \n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class features_dataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, mode, train):\n",
    "\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if train == 0:\n",
    "            #training path\n",
    "            self.night  = glob.glob('/media/godzilla/database/Data8/CVdata/T3/*.mat')\n",
    "\n",
    "\n",
    "        else:\n",
    "            #testing path\n",
    "            self.night  = glob.glob('/media/godzilla/database/Data8/CVdata/V3/*.mat')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        print(len(self.night))\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        \n",
    "        #training result: only check the first 600 epochs\n",
    "        if self.mode == 0:\n",
    "            \n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            # act can be normalized into 0 to 1 like HR\n",
    "            x = (x-x.mean())/x.std()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())\n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            # y0 = np.squeeze(data['stg'])\n",
    "            #y = np.where(y0 == 5, 5, y)\n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "\n",
    "            \n",
    "            x_final = np.zeros((600*30,2))\n",
    "            time = np.zeros((600,5))\n",
    "            y_final = np.zeros((600,1))\n",
    "            z_mask = np.zeros((600,1))\n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "             \n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)\n",
    "            y = np.where(y == 5, 0, y)\n",
    "            #x_final[10*15:,:] = x[:600*15,:]\n",
    "            #y_final[10:,:] = y[:600,:]\n",
    "\n",
    "\n",
    "            s = y.shape[0]\n",
    "\n",
    "\n",
    "            if s >= 600:\n",
    "                x_final[:,0] = x[:600*30,0]\n",
    "                x_final[:,1] = x2[:600*30,0]\n",
    "                y_final[:,:] = y[:600,:]\n",
    "                z_mask[:,:] = z_tmp[:600,:]\n",
    "                time[:,0] = x5[:600,0]\n",
    "                time[:,1] = x3[:600,0]\n",
    "                time[:,2] = x4[:600,0]\n",
    "                time[:,3] = xms[0,:600]\n",
    "                time[:,4] = xms[1,:600]\n",
    "            else:\n",
    "                x_final[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "                x_final[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "                y_final[:y.shape[0],:] = y[:y.shape[0]:]\n",
    "                z_mask[:y.shape[0],:] = z_tmp[:y.shape[0],:]\n",
    "                time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "                time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "                time[:y.shape[0],2] = x4[:y.shape[0],0]\n",
    "                time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "                time[:y.shape[0],4] = xms[1,:y.shape[0]]           \n",
    "        # random crop 600 epochs for training\n",
    "        elif self.mode == 1:\n",
    "\n",
    "\n",
    "            \n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x = (x-x.mean())/x.std()\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            \n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            #x2 = x2/x2.max()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())\n",
    "            #x2 = (x2-x2.mean())/x2.std()\n",
    "\n",
    "            # act can be normalized into 0 to 1 like HR\n",
    "\n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            #y0 = np.squeeze(data['stg'])\n",
    "            # y = np.where(y0 == 5, 5, y)\n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            #print(y.shape)\n",
    "            \n",
    "            #print(x.shape)\n",
    "            #print(y.shape)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)            \n",
    "            y = np.where(y == 5, 0, y)\n",
    "            s = y.shape[0]\n",
    "            \n",
    "            time = np.zeros((1200,5))\n",
    "            #time[:,0] = np.arange(0, 1200, 1, dtype=float)/1200.0\n",
    "            \n",
    "            if s > 1200:\n",
    "            \n",
    "                x_final = np.zeros((1200*30,2))\n",
    "                y_final = np.zeros(((1200),1))\n",
    "                x_final[:,0] = x[:(1200)*30,0]\n",
    "                x_final[:,1] = x2[:(1200)*30,0]\n",
    "                y_final[:,:] = y[:1200,:]\n",
    "                time[:,0] = x5[:1200,0]\n",
    "                time[:,1] = x3[:1200,0]\n",
    "                time[:,2] = x4[:1200,0]                         \n",
    "                time[:,3] = xms[0,:1200]\n",
    "                time[:,4] = xms[1,:1200]\n",
    "                z_mask = z_tmp[:1200,:]   \n",
    "                \n",
    "            else:\n",
    "                x_final = np.zeros(((1200)*30,2))\n",
    "                y_final = np.zeros(((1200),1))\n",
    "                z_mask = np.ones(((1200),1))\n",
    "                #print(x.shape[0])\n",
    "                x_final[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "                x_final[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "                y_final[:y.shape[0],:] = y[:y.shape[0],:]\n",
    "                z_mask[:y.shape[0],:] = z_tmp[:y.shape[0],:]\n",
    "                \n",
    "                time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "                time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "                time[:y.shape[0],2] = x4[:y.shape[0],0] \n",
    "                time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "                time[:y.shape[0],4] = xms[1,:y.shape[0]]\n",
    "\n",
    "            mask_ind = list(range(1200))\n",
    "            random.shuffle(mask_ind)\n",
    "\n",
    "            #z_mask[mask_ind[:1000],:] = 0\n",
    "\n",
    "            # slen_tmp = [50, 100]\n",
    "            # os_ind = random.randint(0, 1)\n",
    "            # os_r = 1200-slen_tmp[os_ind]\n",
    "            # os = random.randint(0, os_r-1)\n",
    "            # z_mask[os:os+slen_tmp[os_ind],:] = 0\n",
    "\n",
    "        #validation\n",
    "        else:\n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x = (x-x.mean())/x.std()\n",
    "            #x2 = np.squeeze(data['act'])\n",
    "            #x2 = (x2-x2.mean())/x2.std()\n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            #x2 = x2/x2.max()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "\n",
    "\n",
    "\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())            \n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            #y0 = np.squeeze(data['stg'])\n",
    "            # y = np.where(y0 == 5, 5, y)           \n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "            \n",
    "            \n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)\n",
    "            y = np.where(y == 5, 0, y)\n",
    "            tem_x = np.zeros((1200*30,2))\n",
    "            tem_y = np.zeros((1200,1))\n",
    "            tem_z = np.zeros((1200,1))\n",
    "            tem_x[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "            tem_x[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "            tem_y[:y.shape[0],:] = y[:,:]\n",
    "            tem_z[:y.shape[0],:] = z_tmp[:,:]\n",
    "            x1 = torch.FloatTensor(tem_x) \n",
    "            y1 = torch.LongTensor(tem_y)\n",
    "            z1 = torch.LongTensor(tem_z)\n",
    "            y11 = torch.LongTensor(np.squeeze(tem_y))\n",
    "            y2 = torch.nn.functional.one_hot(y11, num_classes=4)\n",
    "\n",
    "\n",
    "            time = np.zeros((1200,5))\n",
    "            time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "            time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "            time[:y.shape[0],2] = x4[:y.shape[0],0]  \n",
    "            time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "            time[:y.shape[0],4] = xms[1,:y.shape[0]]\n",
    "            #time[:,0] = np.arange(0, 1200, 1, dtype=float)/1200.0\n",
    "\n",
    "            \n",
    "            time = torch.FloatTensor(time)\n",
    "            return x1, y1, y2, y.shape[0], z1, time\n",
    "        #x = self.input_x[index].reshape((h, w))\n",
    "        #y = self.input_y[index]\t\t\t\n",
    "        #x = x[:,[0, 1, 6]]\t\n",
    "        #x = x[:,:]\n",
    "        x1 = torch.FloatTensor(x_final) \n",
    "        y1 = torch.LongTensor(y_final)\n",
    "        z1 = torch.LongTensor(z_mask)\n",
    "        y11 = torch.LongTensor(np.squeeze(y_final)) \n",
    "        time = torch.FloatTensor(time)\n",
    "\n",
    "        #print(y1.size(), \"                    \"  ,x1.size())\n",
    "\n",
    "        #print y1.size()\n",
    "        #print(y1.size())\n",
    "        \n",
    "        #y2 = torch.zeros(y1.size()[0],4).scatter_(dim=1, index=y1, src=torch.tensor(1.0))\n",
    "        y2 = torch.nn.functional.one_hot(y11, num_classes=4)\n",
    "        #print y2.size()\n",
    "        #quit()\n",
    "        #print(y2.size())\n",
    "        return x1, y1, y2, z1, time\n",
    "    def __len__(self):\n",
    "        if self.mode == 1:\n",
    "            return(len(self.night))\n",
    "        else:\n",
    "            return(len(self.night))\n",
    "            #return(len(self.x))\n",
    "    def getName(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 1, train = 0),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "train_loader2 = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 0, train = 0),\n",
    "    batch_size = BATCH_SIZEV,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 2, train = 1),\n",
    "    batch_size = BATCH_SIZEV2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.random() < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = in_w\n",
    "OUTPUT_DIM = 4\n",
    "ENC_EMB_DIM = in_w\n",
    "DEC_EMB_DIM = 4\n",
    "#HID_DIM = 1\n",
    "#N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.0\n",
    "DEC_DROPOUT = 0.0\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "ENC_HID_DIM = 96\n",
    "\n",
    "DEC_HID_DIM = 96\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "\n",
    "cnnmodel = CNN().to(device)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "cnnmodel = nn.DataParallel(cnnmodel, device_ids=[0, 1])\n",
    "\n",
    "print(cnnmodel)\n",
    "print(model)\n",
    "\n",
    "\n",
    "MAX = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCCLoss(nn.Module):\n",
    "    def __init__(self, fn_weights=None, fp_weights=None):\n",
    "        super(RCCLoss,self).__init__()\n",
    "        #anti_eye = np.ones((k,k)) - np.eye(k)\n",
    "        self.full_fn_weights = torch.Tensor(fn_weights)\n",
    "        self.full_fp_weights = torch.Tensor(fp_weights)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        #print(x.size()[0])\n",
    "        #print(y.size())\n",
    "        #print(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        yi = torch.cuda.LongTensor(y.unsqueeze(1))\n",
    "        #print(yi)\n",
    "        y1 = torch.zeros(x.size()[0],cls).cuda().scatter_(1, yi, 1)\n",
    "        #print(y1)\n",
    "        if y1.type() != x.data.type():\n",
    "            y1 = y1.type_as(x.data)\n",
    "        eps=1e-5\n",
    "        \n",
    "        x = torch.clamp(x, eps, 1. - eps) \n",
    "        \n",
    "        logs = torch.log(x)\n",
    "        \n",
    "        logs_1_sub = torch.log(1.-x) # shape (m, k), dense. 0 is good. \n",
    "        #logs =  F.log_softmax(x)\n",
    "        \n",
    "        #logs_1_sub =  F.log_softmax(1.-x) # shape (m, k), dense. 0 is good. \n",
    "        #print(logs_1_sub)\n",
    "        if self.full_fn_weights.type() != x.data.type():\n",
    "            self.full_fn_weights = self.full_fn_weights.type_as(x.data)\n",
    "\n",
    "        if self.full_fp_weights.type() != x.data.type():\n",
    "            self.full_fp_weights = self.full_fp_weights.type_as(x.data)\n",
    "        \n",
    "        m_full_fn_weights = torch.mm(y1, self.full_fn_weights) # (m,k) . (k, k)\n",
    "        \n",
    "        m_full_fp_weights = torch.mm(y1, self.full_fp_weights) # (m,k) . (k, k)\n",
    "        #print(y1.type())\n",
    "        #print(self.full_fn_weights.type())\n",
    "        #print(m_full_fp_weights.type())\n",
    "        loss = (0.25*m_full_fn_weights * logs + 0.5*m_full_fp_weights * logs_1_sub)\n",
    "        \n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 16433.0\n",
    "l = 63668.0\n",
    "d = 25685.0\n",
    "r = 32015.0\n",
    "aa = w + l + d+ r\n",
    "weights = [1.0/0.0878, 1.0/0.4636, 1.0/0.1940, 1.0/0.2548]\n",
    "fn_weights =[\n",
    " [1.0/0.0878, 0.00, 0.00, 0.00],\n",
    " [0.00, 1.0/0.4636, 0.00, 0.00],\n",
    " [0.00, 0.00, 1.0/0.1940, 0.00],\n",
    " [0.00, 0.00, 0.00, 1.0/0.2548]]\n",
    "fp_weights4= [\n",
    " [0.00, (w/l)**0.5, (w/d)**0.5, (w/r)**0.5],\n",
    " [(l/w)**0.5 * 0.5, 0.00, (l/d)**0.5 *0.5, (l/r)**0.5 ],\n",
    " [(d/w)**0.5, (d/l)**0.5 * 0.5, 0.00, (r/l)**0.5 * 0.5],\n",
    " [(r/w)**0.5 * 0.5, (r/l)**0.5, (r/d)**0.5, 0.00]]\n",
    "\n",
    "loss_func = RCCLoss(fn_weights=fn_weights, fp_weights=fp_weights4)\n",
    "loss_func_CE = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 class : no jitter N800 CE ICF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_t = np.zeros(EPOCH)\n",
    "loss_v = np.zeros(EPOCH)\n",
    "acc_t = np.zeros(EPOCH)\n",
    "acc_v = np.zeros(EPOCH)\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "\n",
    "\n",
    "    LR = 0.0001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    optimizer2 = torch.optim.Adam(cnnmodel.parameters(), lr=LR)\n",
    "    model.train()\n",
    "    cnnmodel.train()\n",
    "\n",
    "    #training\n",
    "\n",
    "    for step, (x, y, y2, z, time) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        y3 = y2\n",
    "        sqe = 1200\n",
    "\n",
    "        \n",
    "\n",
    "        data_in = torch.FloatTensor(BATCH_SIZE, sqe*30, in_w)\n",
    "        data_in2 = torch.FloatTensor(BATCH_SIZE, sqe, 5)\n",
    "        data_out = torch.LongTensor(BATCH_SIZE, 1,1)\n",
    "        data_out3 = torch.LongTensor(BATCH_SIZE, sqe, 1)\n",
    "        data_mask = torch.LongTensor(BATCH_SIZE, sqe, 1)\n",
    "        target = torch.FloatTensor(BATCH_SIZE, sqe, cls)\n",
    "\n",
    "        data_in[:,:,:] = x[:,:sqe*30,:]\n",
    "        data_out3[:,:,:] = y[:,:sqe,:]\n",
    "        data_mask[:,:,:] = z[:,:sqe,:]\n",
    "        data_in2[:,:,:] = time[:,:sqe,:]\n",
    "        \n",
    "        data_out4 = data_out3.squeeze(2).reshape(BATCH_SIZE*(sqe))\n",
    "        data_mask = data_mask.squeeze(2).reshape(BATCH_SIZE*(sqe))\n",
    "        data_out5 = data_out3.squeeze(2).reshape(BATCH_SIZE,(sqe)).permute(1,0)\n",
    "\n",
    "        target[:,:,:] = y3[:,:sqe,:] \n",
    "        t_x = Variable(data_in.to(device))\n",
    "        t_x2 = Variable(data_in2.to(device))\n",
    "\n",
    "\n",
    "        t_y2 = Variable(data_out4.to(device))\n",
    "        t_mask = Variable(data_mask.to(device))\n",
    "        t_y3 = Variable(data_out5.to(device))\n",
    "        trg = Variable(target.to(device))\n",
    "        \n",
    "\n",
    "        tmp = cnnmodel(t_x, t_x2)\n",
    "        \n",
    "\n",
    "        outputs = model(tmp, t_x, trg, 0.0)\n",
    "\n",
    "        _, pred = torch.max(outputs[:,:,:].contiguous().view(-1,cls).data, 1)\n",
    "\n",
    "        loss = loss_func_CE(outputs.contiguous().view(-1,cls), t_y2)\n",
    "        total_loss_CE = torch.sum(loss * t_mask)\n",
    "        loss = loss_func(outputs.contiguous().view(-1,cls), t_y2)\n",
    "        t_mask2 = t_mask.unsqueeze(1).repeat(1,4)\n",
    "        total_loss_RWL = -torch.sum(loss * t_mask2)\n",
    "\n",
    "        total_loss = total_loss_CE + 0.01 * total_loss_RWL\n",
    "\n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        total_loss.backward() \n",
    "\n",
    "        optimizer.step()        # apply gradients\n",
    "        optimizer2.step()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Training done\")\n",
    "    model.eval()\n",
    "    cnnmodel.eval()\n",
    "    if (epoch)%10 == 0:\n",
    "\n",
    "        mse = np.zeros(BATCH_SIZEV)\n",
    "        pmse = np.zeros(BATCH_SIZEV)\n",
    "        count = 0.0\n",
    "        acc = np.zeros(cls)\n",
    "        total = np.zeros(cls)\n",
    "        cf = np.zeros((cls,cls))\n",
    "\n",
    "        for step, (x, y, y2, z, time) in enumerate(train_loader2):\n",
    "            sqe800 = 600\n",
    "            with torch.no_grad():\n",
    "\n",
    "                y3 = y2\n",
    "\n",
    "    \n",
    "                #ii = \n",
    "                data_in = torch.FloatTensor(BATCH_SIZEV, sqe800*30, in_w)\n",
    "                data_in2 = torch.FloatTensor(BATCH_SIZEV, sqe800, 5)\n",
    "                data_out = torch.LongTensor(BATCH_SIZEV, 1,1)\n",
    "                #data_out2 = torch.LongTensor(BATCH_SIZE * sqe)\n",
    "                #data_out3 = torch.LongTensor(BATCH_SIZE, sqe+1, 1)\n",
    "                data_out3 = torch.LongTensor(BATCH_SIZEV, sqe800, 1)\n",
    "                data_mask = torch.LongTensor(BATCH_SIZEV, sqe800, 1)\n",
    "                target = torch.FloatTensor(BATCH_SIZEV, sqe800, cls)\n",
    "                #target2 = torch.FloatTensor(BATCH_SIZE, sqe-1, cls)\n",
    "        \n",
    "                data_in[:,:,:] = x[:,:sqe800*30,:]\n",
    "                data_in2[:,:,:] = time[:,:sqe800,:5]\n",
    "\n",
    "                data_out3[:,:,:] = y[:,:sqe800,:]\n",
    "                data_mask[:,:,:] = z[:,:sqe800,:]\n",
    "                \n",
    "                data_out4 = data_out3.squeeze(2).reshape(BATCH_SIZEV*(sqe800))\n",
    "                data_mask = data_mask.squeeze(2).reshape(BATCH_SIZEV*(sqe800))\n",
    "                data_out5 = data_out3.squeeze(2).reshape(BATCH_SIZEV,(sqe800)).permute(1,0)\n",
    "        \n",
    "                target[:,:,:] = y3[:,:sqe800,:] \n",
    "                t_x = Variable(data_in.to(device))\n",
    "                t_x2 = Variable(data_in2.to(device))\n",
    "                #t_y = Variable(data_out.to(device))\n",
    "                t_y2 = Variable(data_out4.to(device))\n",
    "                t_mask = Variable(data_mask.to(device))\n",
    "                t_y3 = Variable(data_out5.to(device))\n",
    "                trg = Variable(target.to(device))\n",
    "\n",
    "                tmp = cnnmodel(t_x, t_x2)\n",
    "                outputs = model(tmp, t_x, trg, 0.0)\n",
    "\n",
    "\n",
    "                _, pred2 = torch.max(outputs[:,:,:].contiguous().view(-1,cls).data, 1)\n",
    "                plabel = pred2.cpu().data\n",
    "                #print(plabel.size())\n",
    "                \n",
    "                for tt in range(BATCH_SIZEV):\n",
    "                    #if data_out4z[(tt+1)*(sqe-1)-1] == 1:\n",
    "                    for s in range(sqe800):\n",
    "                        if z[tt,s,0] ==1:\n",
    "                            cf[data_out4[(tt*sqe800)+(s)], plabel[(tt*sqe800)+(s)]] +=1\n",
    "                            total[data_out4[(tt*sqe800)+(s)]] +=1\n",
    "                            #print(plabel[tt])\n",
    "                            #print(data_out4[(tt+1)*sqe-1])\n",
    "                            if plabel[(tt*sqe800)+(s)] == data_out4[(tt*sqe800)+(s)]:\n",
    "                                acc[data_out4[(tt*sqe800)+(s)]] += 1\n",
    "                                count += 1\n",
    "               \n",
    "        acc_t[epoch] =count/total.sum()\n",
    "        print(\"Train EPOCH : \", epoch + 1, \" ACC : \", count/total.sum(), \"    LR: \", LR)\n",
    "        print(\"ACC 0 wake : \", acc[0]/total[0], \" ACC 1 stage 1 : \", acc[1]/total[1], \" ACC 2 stage 2 : \", acc[2]/total[2], \" ACC 3 stage 3 : \", acc[3]/total[3])\n",
    "        print(total[0], \"   \", total[1], \"   \", total[2] , \"   \", total[3])\n",
    "        np.set_printoptions(precision=3,suppress=True)\n",
    "        print(\"Train Confusion matrix : \")\n",
    "        print(cf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if (epoch+1)%1 == 0:\n",
    "        mse = np.zeros(BATCH_SIZEV2)\n",
    "        pmse = np.zeros(BATCH_SIZEV2)\n",
    "        count = 0.0\n",
    "        acc = np.zeros(cls)\n",
    "        total = np.zeros(cls)\n",
    "        cf = np.zeros((cls,cls))\n",
    "\n",
    "        sqe1200 = 1200\n",
    "        for step, (x, y, y2, lens, z, time) in enumerate(val_loader):\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "\n",
    "                y3 = y2\n",
    "\n",
    "        \n",
    "                #ii = \n",
    "                data_in = torch.FloatTensor(BATCH_SIZEV2, sqe1200*30, in_w)\n",
    "                data_in2 = torch.FloatTensor(BATCH_SIZEV2, sqe1200, 5)\n",
    "                data_out = torch.LongTensor(BATCH_SIZEV2, 1,1)\n",
    "                data_out3 = torch.LongTensor(BATCH_SIZEV2, sqe1200, 1)\n",
    "                data_mask = torch.LongTensor(BATCH_SIZEV2, sqe1200, 1)\n",
    "                target = torch.FloatTensor(BATCH_SIZEV2, sqe1200, cls)\n",
    "        \n",
    "                data_in[:,:,:] = x[:,:sqe1200*30,:]\n",
    "                data_in2[:,:,:] = time[:,:sqe1200,:5]\n",
    "\n",
    "                data_out3[:,:,:] = y[:,:sqe1200,:]\n",
    "                data_mask[:,:,:] = z[:,:sqe1200,:]\n",
    "                \n",
    "                data_out4 = data_out3.squeeze(2).reshape(BATCH_SIZEV2*(sqe1200))\n",
    "                data_mask = data_mask.squeeze(2).reshape(BATCH_SIZEV2*(sqe1200))\n",
    "                data_out5 = data_out3.squeeze(2).reshape(BATCH_SIZEV2,(sqe1200)).permute(1,0)\n",
    "        \n",
    "                target[:,:,:] = y3[:,:sqe1200,:] \n",
    "                t_x = Variable(data_in.to(device))\n",
    "                t_x2 = Variable(data_in2.to(device))\n",
    "                #t_y = Variable(data_out.to(device))\n",
    "                t_y2 = Variable(data_out4.to(device))\n",
    "                t_mask = Variable(data_mask.to(device))\n",
    "                t_y3 = Variable(data_out5.to(device))\n",
    "                trg = Variable(target.to(device))\n",
    "                tmp = cnnmodel(t_x, t_x2)\n",
    "                outputs = model(tmp, t_x,trg, 0.0)\n",
    "\n",
    "                _, pred2 = torch.max(outputs[:,:,:].contiguous().view(-1,cls).data, 1)\n",
    "                plabel = pred2.cpu().data\n",
    "                for tt in range(BATCH_SIZEV2):\n",
    "\n",
    "                    #if data_out4z[(tt+1)*(sqe-1)-1] == 1:\n",
    "                    l = lens[tt]\n",
    "                    for s in range(l):\n",
    "                        if z[tt,s,0] ==1:\n",
    "                            cf[data_out4[(tt*sqe1200)+(s)], plabel[(tt*sqe1200)+(s)]] +=1\n",
    "                            total[data_out4[(tt*sqe1200)+(s)]] +=1\n",
    "                            if plabel[(tt*sqe1200)+(s)] == data_out4[(tt*sqe1200)+(s)]:\n",
    "                                acc[data_out4[(tt*sqe1200)+(s)]] += 1\n",
    "                                count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        acc_v[epoch] = count/total.sum()                   \n",
    "        print(\"Val Mode EPOCH : \", epoch + 1, \" ACCV : \", count/total.sum(), \"    LR: \", LR)\n",
    "        print(\"ACC 0 Vwake : \", acc[0]/total[0], \" ACC 1 stage V1 : \", acc[1]/total[1], \" ACC 2 stage V2 : \", acc[2]/total[2], \" ACC 3 stage V3 : \", acc[3]/total[3])\n",
    "        print(total[0], \"   \", total[1], \"   \", total[2] , \"   \", total[3])\n",
    "\n",
    "\n",
    "\n",
    "        np.set_printoptions(precision=3,suppress=True)\n",
    "        print(\"Val Mode Confusion matrix : \")\n",
    "        print(cf)\n",
    "\n",
    "        #Saving model\n",
    "        #SAVE_PATH_CNN = \"/CNN_LSTM_Epoch_\" + str(epoch + 1) + \".pkl\"\n",
    "        #SAVE_PATH_S2S = \"/S2S_Epoch_\" + str(epoch + 1) + \".pkl\"\n",
    "        #torch.save(cnnmodel.state_dict(), SAVE_PATH_CNN)\n",
    "        #torch.save(model.state_dict(), SAVE_PATH_S2S)\n",
    "        #print(\"Model saved!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tas",
   "language": "python",
   "name": "tas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
