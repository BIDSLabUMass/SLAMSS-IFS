{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godzilla/anaconda3/envs/pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "from torchvision.datasets.folder import IMG_EXTENSIONS\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from numpy import load\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10#100\n",
    "BATCH_SIZEV = 13#560\n",
    "BATCH_SIZEV2 = 32\n",
    "\n",
    "# longest epoch len in the validation set\n",
    "len_val = 1150\n",
    "EPOCH = 1000\n",
    "h = 600\n",
    "w = 2\n",
    "in_w = 2\n",
    "sqe = 1200 # can try 5\n",
    "cls = 4\n",
    "crop = 600#1240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode_micro(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encode_micro, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(2, 32, 2, bidirectional = True, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(32*2, 128),\n",
    "            #nn.BatchNorm1d(dec_hid_dim),\n",
    "            #nn.Dropout(0.5),\n",
    "        )\n",
    "     \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "\n",
    "\n",
    "        outputs, hidden = self.rnn(src)\n",
    "\n",
    "\n",
    "        hidden = self.fc(outputs[:,-1,:])\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.GRU(2, 64, 3, bidirectional = True, dropout=0.5, batch_first = True)\n",
    "        \n",
    "        self.cnn = nn.Sequential( \n",
    "        nn.Conv1d(2, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.MaxPool1d(6, stride=6),#60\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        #nn.Dropout(0.5),\n",
    "        #nn.MaxPool1d(3, stride=3),#20\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.MaxPool1d(5, stride=5),#10\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        # #nn.MaxPool1d(2, stride=2),#5\n",
    "        nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # #nn.MaxPool1d(2, stride=2),#2\n",
    "        # nn.Conv1d(128, 256, 9, stride=1, padding=4),     \n",
    "        nn.Dropout(0.5),\n",
    "        #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        )\n",
    "\n",
    "        # self.cnn2 = nn.Sequential(\n",
    "            \n",
    "        # nn.Conv1d(in_w, 128, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # nn.MaxPool1d(6, stride=6),#60\n",
    "        # nn.Conv1d(128, 128, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # #nn.Dropout(0.5),\n",
    "        # #nn.MaxPool1d(3, stride=3),#20\n",
    "        # nn.Conv1d(128, 128, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # nn.MaxPool1d(5, stride=5),#10\n",
    "        # nn.Conv1d(128, 128, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # # #nn.MaxPool1d(2, stride=2),#5\n",
    "        # nn.Conv1d(128, 128, 3, stride=1, padding=1),\n",
    "        # # nn.LeakyReLU(inplace=False),\n",
    "        # # #nn.MaxPool1d(2, stride=2),#2\n",
    "        # # nn.Conv1d(128, 256, 9, stride=1, padding=4),     \n",
    "        # nn.Dropout(0.5),\n",
    "        # #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        # )\n",
    "        # self.fc = nn.Sequential( \n",
    "        #     nn.Linear(256, 128),\n",
    "        #     nn.LeakyReLU(inplace=False),\n",
    "        #     nn.Linear(128, 128),\n",
    "        #     #nn.BatchNorm1d(dec_hid_dim),\n",
    "        #     #nn.Dropout(0.5),\n",
    "        # )    \n",
    "        # self.cnn = nn.Sequential( \n",
    "        # nn.Conv1d(in_w, 64, 15, stride=1, padding=7),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # nn.MaxPool1d(6, stride=6),#60\n",
    "        # nn.Conv1d(64, 64, 9, stride=1, padding=4),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # #nn.Dropout(0.5),\n",
    "        # #nn.MaxPool1d(3, stride=3),#20\n",
    "        # nn.Conv1d(64, 64, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # nn.MaxPool1d(5, stride=5),#10\n",
    "        # nn.Conv1d(64, 64, 3, stride=1, padding=1),\n",
    "        # nn.LeakyReLU(inplace=False),\n",
    "        # # #nn.MaxPool1d(2, stride=2),#5\n",
    "        # nn.Conv1d(64, 64, 3, stride=1, padding=1),\n",
    "        # # nn.LeakyReLU(inplace=False),\n",
    "        # # #nn.MaxPool1d(2, stride=2),#2\n",
    "        # # nn.Conv1d(128, 256, 9, stride=1, padding=4),     \n",
    "        # nn.Dropout(0.5),\n",
    "        # #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        self.cnn_ACT = nn.Sequential( \n",
    "        nn.Conv1d(5, 16, 9, stride=1, padding=4),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(16, 32, 9, stride=1, padding=4),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(32, 64, 9, stride=1, padding=4),\n",
    "        #nn.LeakyReLU(inplace=False),\n",
    "        nn.Dropout(0.5),\n",
    "        #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential( \n",
    "        nn.Conv1d(128+64+128, 256, 11, stride=1, padding=5),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(256, 256, 15, stride=1, padding=7),\n",
    "        nn.LeakyReLU(inplace=False),\n",
    "        nn.Conv1d(256, 512, 21, stride=1, padding=10),\n",
    "        #nn.LeakyReLU(inplace=False),\n",
    "        #nn.Conv1d(512, 512, 31, stride=1, padding=15),\n",
    "        #nn.LeakyReLU(inplace=False),\n",
    "        nn.Dropout(0.5),\n",
    "        #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        )\n",
    "    \n",
    "        # self.cnn2 = nn.Sequential( \n",
    "        # nn.Conv1d(33, 32, 15, stride=15, padding=7),\n",
    "\n",
    "\n",
    "        # #nn.LeakyReLU(inplace=False), #put it back 2020 706\n",
    "        # )\n",
    "        \n",
    "    def forward(self, src, time):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "        #embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src sent len, batch size, emb dim]\n",
    "        #print(src.size())\n",
    "        #print src\n",
    "\n",
    "        src1 = src.permute(0, 2, 1)\n",
    "        src11 = time.permute(0, 2, 1)\n",
    "        #print(src1.size())\n",
    "        src2 = self.cnn(src1)\n",
    "\n",
    "        outputs, hidden = self.rnn(src)\n",
    "        outputs = outputs[:,::30,:]\n",
    "        src22 = outputs.permute(0, 2, 1)\n",
    "        #print(src22.size())\n",
    "        #src22 = self.cnn2(src1)\n",
    "        #tensor to store encoder micro outputs\n",
    "        # batch_size = src.size()[0]\n",
    "        # max_len = time.size()[1]\n",
    "        # outputs = torch.zeros(batch_size, max_len, 64).to('cuda')\n",
    "        # for i in range(max_len):\n",
    "        #     out, hid = self.rnn(src[:,i*30:(i+1)*30,:])\n",
    "        #     outputs[:,i,:] = hid[:,:]\n",
    "               \n",
    "        src222 = self.cnn_ACT(src11)\n",
    "        #print src2.size()\n",
    "        #outputs2 = outputs.permute(0, 2, 1)\n",
    "        #src3= torch.cat((src11 src2),1)\n",
    "        src3= torch.cat((src2, src22, src222),1)\n",
    "        src4 = self.cnn3(src3)\n",
    "        src4= torch.cat((src4, src11[:,:,:]),1)\n",
    "        src5 = src4.permute(0, 2, 1)\n",
    "        \n",
    "        #src5= torch.cat((src4, act),2)\n",
    "        \n",
    "        #print(src2.size())\n",
    "        #print(act.size())\n",
    "        #src5= torch.cat((src2, time),2)\n",
    "        return src5\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 1) + dec_hid_dim, dec_hid_dim, bias=True)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        \n",
    "        #repeat encoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.rnn = nn.GRU(512+5, enc_hid_dim, 1, bidirectional = False, dropout=0.2, batch_first = True)\n",
    "        \n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(enc_hid_dim * 1, dec_hid_dim, bias=True),\n",
    "            #nn.BatchNorm1d(dec_hid_dim),\n",
    "            #nn.Dropout(0.5),\n",
    "        )\n",
    "     \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "\n",
    "\n",
    "        outputs, hidden = self.rnn(src)\n",
    "\n",
    "\n",
    "        hidden = self.fc(hidden[-1,:,:])\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        #self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        \n",
    "        #self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        #self.rnn = nn.GRU( emb_dim, dec_hid_dim,1, bidirectional = False, batch_first = True, dropout=0.5)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 1 ) + emb_dim, dec_hid_dim,1, bidirectional = False, batch_first = True, dropout=0.2)\n",
    "        self.out = nn.Sequential( \n",
    "\n",
    "            nn.Linear((enc_hid_dim * 1) + dec_hid_dim + emb_dim + 512+5 + 128, output_dim),\n",
    "            #nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, cnnf, micro):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        #print a        \n",
    "        #a = [batch size, src len]\n",
    "    \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        encoder_outputs = encoder_outputs.permute(0, 1, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "\n",
    "        rnn_input = torch.cat((input, weighted), dim = 2)\n",
    "        #rnn_input = input\n",
    "        rnn_input = rnn_input.permute(1, 0, 2)\n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "        #print hidden.size()\n",
    "        #print(hidden.size())\n",
    "        #print(rnn_input.size())\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "\n",
    "        output = output.squeeze(1)\n",
    "        output = output.unsqueeze(0)\n",
    "        cnnf = cnnf.unsqueeze(0)\n",
    "        micro=micro.unsqueeze(0)\n",
    "        #print(output.size())\n",
    "        #print(cnnf.size())\n",
    "        output = self.out(torch.cat((output, weighted, input, cnnf, micro), dim = 2))\n",
    "\n",
    "        return output, hidden.squeeze(0)\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device = 0):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.rnn = Encode_micro()\n",
    "        print(self.device)\n",
    "\n",
    "        \n",
    "    def forward(self, src, src2, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        #print(src.size()) #b s f\n",
    "        batch_size = trg.shape[0]\n",
    "        max_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        #print hidden.size()\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[:,0]\n",
    "        #_, ind = torch.max(input,1)\n",
    "        #print(\"trg:\", trg.size())\n",
    "        #print(input.size())\n",
    "        #print(input2.size())\n",
    "\n",
    "\n",
    "\n",
    "        #tensor to store encoder micro outputs\n",
    "\n",
    "        #outputs2 = torch.zeros(batch_size, max_len, 64).to('cuda')\n",
    "        \n",
    "\n",
    "        \n",
    "        for t in range(0, max_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "\n",
    "\n",
    "            out, hid = self.rnn(src2[:,t*30:(t+1)*30,:])\n",
    "            #outputs2[:,i,:] = hid[:,:]\n",
    "\n",
    "            \n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs, src[:,t,:],hid)\n",
    "\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            if output.size()[0] == 1:\n",
    "                outputs[:,t,:] = output[:,:]\n",
    "            else:\n",
    "                outputs[:,t,:] = output[:,0,:]\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            #need to chekc again   tzuan\n",
    "            #top1 = output.argmax(1)\n",
    "            #top1 = top1.view(-1,1).type(torch.cuda.FloatTensor)\n",
    "            #print \"Tp: \", top1.size()\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[:,t] if teacher_force else output.squeeze(0)\n",
    "        \n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class features_dataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, mode, train):\n",
    "\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if train == 0:\n",
    "            #training path\n",
    "            self.night  = glob.glob('/media/godzilla/database/Data8/Train_test2_20/*.mat')\n",
    "\n",
    "\n",
    "        else:\n",
    "            #testing path\n",
    "            self.night  = glob.glob('/media/godzilla/database/Data8/Val_test2/*.mat')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        print(len(self.night))\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        \n",
    "        #training result: only check the first 600 epochs\n",
    "        if self.mode == 0:\n",
    "            \n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            # act can be normalized into 0 to 1 like HR\n",
    "            x = (x-x.mean())/x.std()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())\n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            # y0 = np.squeeze(data['stg'])\n",
    "            #y = np.where(y0 == 5, 5, y)\n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "\n",
    "            \n",
    "            x_final = np.zeros((600*30,2))\n",
    "            time = np.zeros((600,5))\n",
    "            y_final = np.zeros((600,1))\n",
    "            z_mask = np.zeros((600,1))\n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "             \n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)\n",
    "            y = np.where(y == 5, 0, y)\n",
    "            #x_final[10*15:,:] = x[:600*15,:]\n",
    "            #y_final[10:,:] = y[:600,:]\n",
    "\n",
    "\n",
    "            s = y.shape[0]\n",
    "\n",
    "\n",
    "            if s >= 600:\n",
    "                x_final[:,0] = x[:600*30,0]\n",
    "                x_final[:,1] = x2[:600*30,0]\n",
    "                y_final[:,:] = y[:600,:]\n",
    "                z_mask[:,:] = z_tmp[:600,:]\n",
    "                time[:,0] = x5[:600,0]\n",
    "                time[:,1] = x3[:600,0]\n",
    "                time[:,2] = x4[:600,0]\n",
    "                time[:,3] = xms[0,:600]\n",
    "                time[:,4] = xms[1,:600]\n",
    "            else:\n",
    "                x_final[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "                x_final[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "                y_final[:y.shape[0],:] = y[:y.shape[0]:]\n",
    "                z_mask[:y.shape[0],:] = z_tmp[:y.shape[0],:]\n",
    "                time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "                time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "                time[:y.shape[0],2] = x4[:y.shape[0],0]\n",
    "                time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "                time[:y.shape[0],4] = xms[1,:y.shape[0]]           \n",
    "        # random crop 600 epochs for training\n",
    "        elif self.mode == 1:\n",
    "\n",
    "\n",
    "            \n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x = (x-x.mean())/x.std()\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            \n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            #x2 = x2/x2.max()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())\n",
    "            #x2 = (x2-x2.mean())/x2.std()\n",
    "\n",
    "            # act can be normalized into 0 to 1 like HR\n",
    "\n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            #y0 = np.squeeze(data['stg'])\n",
    "            # y = np.where(y0 == 5, 5, y)\n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            #print(y.shape)\n",
    "            \n",
    "            #print(x.shape)\n",
    "            #print(y.shape)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)            \n",
    "            y = np.where(y == 5, 0, y)\n",
    "            s = y.shape[0]\n",
    "            \n",
    "            time = np.zeros((1200,5))\n",
    "            #time[:,0] = np.arange(0, 1200, 1, dtype=float)/1200.0\n",
    "            \n",
    "            if s > 1200:\n",
    "            \n",
    "                x_final = np.zeros((1200*30,2))\n",
    "                y_final = np.zeros(((1200),1))\n",
    "                x_final[:,0] = x[:(1200)*30,0]\n",
    "                x_final[:,1] = x2[:(1200)*30,0]\n",
    "                y_final[:,:] = y[:1200,:]\n",
    "                time[:,0] = x5[:1200,0]\n",
    "                time[:,1] = x3[:1200,0]\n",
    "                time[:,2] = x4[:1200,0]                         \n",
    "                time[:,3] = xms[0,:1200]\n",
    "                time[:,4] = xms[1,:1200]\n",
    "                z_mask = z_tmp[:1200,:]   \n",
    "                \n",
    "            else:\n",
    "                x_final = np.zeros(((1200)*30,2))\n",
    "                y_final = np.zeros(((1200),1))\n",
    "                z_mask = np.ones(((1200),1))\n",
    "                #print(x.shape[0])\n",
    "                x_final[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "                x_final[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "                y_final[:y.shape[0],:] = y[:y.shape[0],:]\n",
    "                z_mask[:y.shape[0],:] = z_tmp[:y.shape[0],:]\n",
    "                \n",
    "                time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "                time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "                time[:y.shape[0],2] = x4[:y.shape[0],0] \n",
    "                time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "                time[:y.shape[0],4] = xms[1,:y.shape[0]]\n",
    "\n",
    "            mask_ind = list(range(1200))\n",
    "            random.shuffle(mask_ind)\n",
    "\n",
    "            #z_mask[mask_ind[:1000],:] = 0\n",
    "\n",
    "            # slen_tmp = [50, 100]\n",
    "            # os_ind = random.randint(0, 1)\n",
    "            # os_r = 1200-slen_tmp[os_ind]\n",
    "            # os = random.randint(0, os_r-1)\n",
    "            # z_mask[os:os+slen_tmp[os_ind],:] = 0\n",
    "\n",
    "        #validation\n",
    "        else:\n",
    "            data = scipy.io.loadmat(self.night[index])\n",
    "            x = np.squeeze(data['hr'])/60.0\n",
    "            xms = np.squeeze(data['hr2'])/60.0\n",
    "            x = (x-x.mean())/x.std()\n",
    "            #x2 = np.squeeze(data['act'])\n",
    "            #x2 = (x2-x2.mean())/x2.std()\n",
    "            x2 = np.squeeze(data['act'])\n",
    "            x3 = np.squeeze(data['clock'])\n",
    "            x4 = np.squeeze(data['time'])\n",
    "            x5 = np.squeeze(data['hz'])\n",
    "            #x2 = x2/x2.max()\n",
    "            x2 = (x2-x2.mean())/x2.std()\n",
    "\n",
    "\n",
    "\n",
    "            #x = (x-x.min())/(x.max()-x.min())\n",
    "            #x2 = (x2-x2.min())/(x2.max()-x2.min())            \n",
    "            y = np.squeeze(data['stg_cor_cln'])\n",
    "            #y0 = np.squeeze(data['stg'])\n",
    "            # y = np.where(y0 == 5, 5, y)           \n",
    "            # y = np.where(y0 == 0, 0, y)\n",
    "            # y = np.where(y0 == 4, 4, y)\n",
    "            # y = np.where(y0 == 3, 3, y)\n",
    "            # y = np.where(y0 == 1, 1, y)\n",
    "            x = np.expand_dims(np.squeeze(x), axis=1)\n",
    "            x2 = np.expand_dims(np.squeeze(x2), axis=1)\n",
    "            x3 = np.expand_dims(np.squeeze(x3), axis=1)\n",
    "            x4 = np.expand_dims(np.squeeze(x4), axis=1)\n",
    "            x5 = np.expand_dims(np.squeeze(x5), axis=1)\n",
    "            y = np.expand_dims(np.squeeze(y), axis=1)\n",
    "            \n",
    "            \n",
    "            z_tmp = y\n",
    "            z_tmp = np.where(z_tmp < 5, 1, z_tmp)\n",
    "            z_tmp = np.where(z_tmp == 5, 0, z_tmp)\n",
    "            #y = np.where(y == 1, 0, y)\n",
    "            y = np.where(y == 2, 1, y)\n",
    "            y = np.where(y == 3, 2, y)\n",
    "            y = np.where(y == 4, 3, y)\n",
    "            y = np.where(y == 5, 0, y)\n",
    "            tem_x = np.zeros((1200*30,2))\n",
    "            tem_y = np.zeros((1200,1))\n",
    "            tem_z = np.zeros((1200,1))\n",
    "            tem_x[:x.shape[0],0] = x[:x.shape[0],0]\n",
    "            tem_x[:x2.shape[0],1] = x2[:x2.shape[0],0]\n",
    "            tem_y[:y.shape[0],:] = y[:,:]\n",
    "            tem_z[:y.shape[0],:] = z_tmp[:,:]\n",
    "            x1 = torch.FloatTensor(tem_x) \n",
    "            y1 = torch.LongTensor(tem_y)\n",
    "            z1 = torch.LongTensor(tem_z)\n",
    "            y11 = torch.LongTensor(np.squeeze(tem_y))\n",
    "            y2 = torch.nn.functional.one_hot(y11, num_classes=4)\n",
    "\n",
    "\n",
    "            time = np.zeros((1200,5))\n",
    "            time[:y.shape[0],0] = x5[:y.shape[0],0]\n",
    "            time[:y.shape[0],1] = x3[:y.shape[0],0]\n",
    "            time[:y.shape[0],2] = x4[:y.shape[0],0]  \n",
    "            time[:y.shape[0],3] = xms[0,:y.shape[0]]\n",
    "            time[:y.shape[0],4] = xms[1,:y.shape[0]]\n",
    "            #time[:,0] = np.arange(0, 1200, 1, dtype=float)/1200.0\n",
    "\n",
    "            \n",
    "            time = torch.FloatTensor(time)\n",
    "            return x1, y1, y2, y.shape[0], z1, time\n",
    "        #x = self.input_x[index].reshape((h, w))\n",
    "        #y = self.input_y[index]\t\t\t\n",
    "        #x = x[:,[0, 1, 6]]\t\n",
    "        #x = x[:,:]\n",
    "        x1 = torch.FloatTensor(x_final) \n",
    "        y1 = torch.LongTensor(y_final)\n",
    "        z1 = torch.LongTensor(z_mask)\n",
    "        y11 = torch.LongTensor(np.squeeze(y_final)) \n",
    "        time = torch.FloatTensor(time)\n",
    "\n",
    "        #print(y1.size(), \"                    \"  ,x1.size())\n",
    "\n",
    "        #print y1.size()\n",
    "        #print(y1.size())\n",
    "        \n",
    "        #y2 = torch.zeros(y1.size()[0],4).scatter_(dim=1, index=y1, src=torch.tensor(1.0))\n",
    "        y2 = torch.nn.functional.one_hot(y11, num_classes=4)\n",
    "        #print y2.size()\n",
    "        #quit()\n",
    "        #print(y2.size())\n",
    "        return x1, y1, y2, z1, time\n",
    "    def __len__(self):\n",
    "        if self.mode == 1:\n",
    "            return(len(self.night))\n",
    "        else:\n",
    "            return(len(self.night))\n",
    "            #return(len(self.x))\n",
    "    def getName(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "189\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 1, train = 0),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "train_loader2 = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 0, train = 0),\n",
    "    batch_size = BATCH_SIZEV,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    features_dataset(mode = 2, train = 1),\n",
    "    batch_size = BATCH_SIZEV2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godzilla/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = in_w\n",
    "OUTPUT_DIM = 4\n",
    "ENC_EMB_DIM = in_w\n",
    "DEC_EMB_DIM = 4\n",
    "#HID_DIM = 1\n",
    "#N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.0\n",
    "DEC_DROPOUT = 0.0\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "ENC_HID_DIM = 96\n",
    "\n",
    "DEC_HID_DIM = 96\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "\n",
    "#cnnmodel_pre = CNN_pre().to(device)\n",
    "cnnmodel = CNN().to(device)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "cnnmodel = nn.DataParallel(cnnmodel, device_ids=[0, 1])\n",
    "model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "SAVE_PATH_CNN = \"/media/godzilla/database/s2s_AW_model2/AW_new_freq2_v12/CNN_4cls_part1_layer3_std_sqe_12_Epoch_77.pkl\"\n",
    "SAVE_PATH_S2S = \"/media/godzilla/database/s2s_AW_model2/AW_new_freq2_v12/S2S_4cls_part2_layer3_std_sqe_12_Epoch_77.pkl\"\n",
    "\n",
    "cnnmodel.load_state_dict(torch.load(SAVE_PATH_CNN)) \n",
    "model.load_state_dict(torch.load(SAVE_PATH_S2S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mode ACCV :  0.7142908906442496\n",
      "ACC 0 Vwake :  0.608875128998968  ACC 1 stage V1 :  0.7183373701070396  ACC 2 stage V2 :  0.7490702863518036  ACC 3 stage V3 :  0.7166535686218476\n",
      "4845.0     25598.0     10756.0     13997.0\n",
      "Val Mode Confusion matrix : \n",
      "[[ 2950.  1118.   155.   622.]\n",
      " [ 1406. 18388.  2166.  3638.]\n",
      " [  194.  2329.  8057.   176.]\n",
      " [  707.  3046.   213. 10031.]]\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "acc = np.zeros(cls)\n",
    "total = np.zeros(cls)\n",
    "cf = np.zeros((cls,cls))\n",
    "\n",
    "\n",
    "outprob = np.zeros((64, 1200, 4))\n",
    "outpred = np.zeros((64, 1200))\n",
    "label = np.zeros((64, 1200))\n",
    "mask = np.zeros((64, 1200))\n",
    "length = np.zeros((64))\n",
    "\n",
    "\n",
    "sqe1200 = 1200\n",
    "\n",
    "model.eval()\n",
    "cnnmodel.eval()\n",
    "\n",
    "for step, (x, y, y2, lens, z, time) in enumerate(val_loader):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "\n",
    "        y3 = y2\n",
    "\n",
    "\n",
    "        #ii = \n",
    "        data_in = torch.FloatTensor(BATCH_SIZEV2, sqe1200*30, in_w)\n",
    "        data_in2 = torch.FloatTensor(BATCH_SIZEV2, sqe1200, 3)\n",
    "        data_out = torch.LongTensor(BATCH_SIZEV2, 1,1)\n",
    "        #data_out2 = torch.LongTensor(BATCH_SIZE * sqe)\n",
    "        #data_out3 = torch.LongTensor(BATCH_SIZE, sqe+1, 1)\n",
    "        data_out3 = torch.LongTensor(BATCH_SIZEV2, sqe1200, 1)\n",
    "        data_mask = torch.LongTensor(BATCH_SIZEV2, sqe1200, 1)\n",
    "        target = torch.FloatTensor(BATCH_SIZEV2, sqe1200, cls)\n",
    "        #target2 = torch.FloatTensor(BATCH_SIZE, sqe-1, cls)\n",
    "\n",
    "        data_in[:,:,:] = x[:,:sqe1200*30,:]\n",
    "        data_in2[:,:,:] = time[:,:sqe1200,:3]\n",
    "\n",
    "        data_out3[:,:,:] = y[:,:sqe1200,:]\n",
    "        data_mask[:,:,:] = z[:,:sqe1200,:]\n",
    "        \n",
    "        data_out4 = data_out3.squeeze(2).reshape(BATCH_SIZEV2*(sqe1200))\n",
    "        data_mask = data_mask.squeeze(2).reshape(BATCH_SIZEV2*(sqe1200))\n",
    "        data_out5 = data_out3.squeeze(2).reshape(BATCH_SIZEV2,(sqe1200)).permute(1,0)\n",
    "\n",
    "        target[:,:,:] = y3[:,:sqe1200,:] \n",
    "        t_x = Variable(data_in.to(device))\n",
    "        t_x2 = Variable(data_in2.to(device))\n",
    "        #t_y = Variable(data_out.to(device))\n",
    "        t_y2 = Variable(data_out4.to(device))\n",
    "        t_mask = Variable(data_mask.to(device))\n",
    "        t_y3 = Variable(data_out5.to(device))\n",
    "        trg = Variable(target.to(device))\n",
    "        #trg2 = Variable(target2.to(device))\n",
    "        \n",
    "        #print(t_x.size())\n",
    "        #t_x, t_x2  = cnnmodel_pre(t_x, t_x2)\n",
    "        tmp = cnnmodel(t_x, t_x2)\n",
    "        \n",
    "        #print(tmp.size())\n",
    "        outputs = model(tmp, t_x,trg, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        _, pred2 = torch.max(outputs[:,:,:].contiguous().view(-1,cls).data, 1)\n",
    "        _, pred3 = torch.max(outputs[:,:,:].contiguous().data, 2)\n",
    "        plabel = pred2.cpu().data\n",
    "\n",
    "        outprob[step*BATCH_SIZEV2:(step+1)*BATCH_SIZEV2,:,:] = outputs.cpu().data\n",
    "        outpred[step*BATCH_SIZEV2:(step+1)*BATCH_SIZEV2,:] = pred3.cpu().data\n",
    "        label[step*BATCH_SIZEV2:(step+1)*BATCH_SIZEV2,:] = y[:,:,0]\n",
    "        mask[step*BATCH_SIZEV2:(step+1)*BATCH_SIZEV2,:] = z[:,:,0]\n",
    "        length[step*BATCH_SIZEV2:(step+1)*BATCH_SIZEV2] = lens\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for tt in range(BATCH_SIZEV2):\n",
    "\n",
    "            #if data_out4z[(tt+1)*(sqe-1)-1] == 1:\n",
    "            l = lens[tt]\n",
    "            for s in range(l):\n",
    "                if z[tt,s,0] ==1:\n",
    "                    cf[data_out4[(tt*sqe1200)+(s)], plabel[(tt*sqe1200)+(s)]] +=1\n",
    "                    total[data_out4[(tt*sqe1200)+(s)]] +=1\n",
    "                    if plabel[(tt*sqe1200)+(s)] == data_out4[(tt*sqe1200)+(s)]:\n",
    "                        acc[data_out4[(tt*sqe1200)+(s)]] += 1\n",
    "                        count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "print(\"Val Mode ACCV : \", count/total.sum())\n",
    "print(\"ACC 0 Vwake : \", acc[0]/total[0], \" ACC 1 stage V1 : \", acc[1]/total[1], \" ACC 2 stage V2 : \", acc[2]/total[2], \" ACC 3 stage V3 : \", acc[3]/total[3])\n",
    "print(total[0], \"   \", total[1], \"   \", total[2] , \"   \", total[3])\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "print(\"Val Mode Confusion matrix : \")\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = \"/media/godzilla/database/prediction_results/SLAMSS_77.mat\"\n",
    "scipy.io.savemat(savename, {'prob': outprob, 'pred': outpred, 'stage' : label, 'mask' : mask, 'len' : length })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tas",
   "language": "python",
   "name": "tas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
